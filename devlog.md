# Go Reader Interface Processor

## 1/12
I chose a nested pattern for the project structure over a flat structure in order to separate concerns into routing and data structures. Spent quite some time deciding on what to use for a front-end, but in the end  I decided to move away from a tui application and will use the html/template from the standard library to handle a "card view" rendering for the blog posts. I put some minimal code in the main.go as well as the handlers.go and the blog.go. One of the main challenges today was that I am used to working in a flat structure. I instinctively made a duplicate main.go file in the root of the project. It took me a little time to figure out why i was getting import errors.  One other note about this project is that I will be using multiple machines to write the code. So, I will be using mainly pull and push git commands. I don't really see a need for using branches at this time but this may change.

## 1/13
Today had some growing pains working in a nested structure versus a flat structure that many tutorials and guided projects have. I think I have overcome most of that now by organizing the project into internal/logic for the engine and internal/handlers for the web logic. The largest part of my time today was spent on the logic. I started with just one API call to Dev.to, as its API is pretty simple. In the "logic" part of the project, I defined a Source interface to keep things flexible.
As far as structs go, I created a DevTo struct and a Search method to handle the Dev.to API calls and JSON parsing. I’m currently weighing if there is a cleaner way to do this or if it’s better to have a different struct for every API call, but for now, the interface handles it well. As far as searching goes today, I just hardcoded the query "golang" in the handler to easily test the connectivity and parsing logic. All seems to work fine, though the wiring between the main package and the handlers package required some careful dependency injection to get the engine running.
I also created an index.html using the html/template package from the Go standard library for a simple UI. All rendering is done server-side, which keeps the project lightweight. I have checks in place, like template.Must and proper error wrapping, to crash the app immediately if there’s a failure. This helps save me from memory leaks—thanks to defer resp.Body.Close()—and ensures I'm not unintentionally ddosing the API with bad requests if the setup is broken.

## 1/14 
Today I added a second struct and method to handle HackerNews and implemented the engine logic in main.go. I was able to just plug the new HackerNews logic right into the Engine slice in main.go
One thing I’m noticing now is that the results are just grouped by site Dev.to results show up first, then all the HackerNews ones. I’ve been thinking about a sorting method to list everything by date published instead of just by site. 

## 1/15
Accomplished quite a but today. I implemented concurrency into the project. Before GRIP would process the external APIs sequentially the response time was around 1000ms for only 2 external API searches. I added wait group and channels now it is returning results at a sub 500ms response time for 3 external searches. Big hurdle today was the adding of Hashnode to the api calls. The piping is in place so the complexity for me came from dealing with GraphQL. The api was very strict and I had to make several changes - I made a function that "stringified" AKA slugified in order to normalize user input. I also was able to add sorting into the project so that the results were return by date posted, not by site published on. I am also looking at using Swag for the documentation. 

## 1/16
Today I added Boot.dev as a source. Since this is an RSS feed rather than a standard API, I checked their robots.txt first. I saw that the User-Agent was set to * with no Disallow rules for the feed. I also made sure to identify my crawler in the headers, sending them my GitHub repo URL and my email so they know who is hitting their server.
While adding boot.dev, I ran into a bug caused by a simple typo—I had written parsedata instead of parseData. My code had a saftety clause that used time.Now() if the parsing failed or the return was nil. Because the engine sorts by timestamp, these "failed" posts were all marked with the current time, making them appear as the newest possible results. This drowned out everything else, causing the app to return nothing but posts from Boot.dev.
Once I fixed that, I realized the current structure wasn't scalable at all. I created a refactor branch, moved the logic into a Source package, and set up a Source interface to seperate the engine from the individual providers. I also implemented connection pooling and an automatic leaderboard, which brought my response times down to about 400ms (it had spiked to 671ms after adding Boot.dev). Finally, I imported Swag to handle the API documentation automatically.  

## 1/17
Today was a length day for me.  Found myself scrolling a bit. However, I did magane to add two more sources to Grip, both using JSON data. I kept it simple by using the DevTo source as a template and just changing the structs to match the data returned from each specific API. It was a simple two line addition to add Lobste.rs and FreeCodeCamp into the main engine.

## 1/18
Spent alot of time changing desktop enviroments and trying a different IDE to see I can work a bit quicker without the vim mistakes. For the project today i debugged the freecodecamp source because it was using hashnode so I refactored the original FCC source to take graphql instead of json data. I am pondering whether to add any more sources. Since the logic is in place, it is turning into a simple copy and paste from one source to another and making some minor changes ie urls, struct fields and names. As of right now the project can read and sort json, graphql, rss and xml. and has six sources. So, I think I will start refactoring and refining the structure.

## 1/20
Spent the day rethinking my sorting logic and made some minor changes. Not alot of actual writing of code today in the project. Spent more time thinking of the articiture. I did notice that I was not using a pointer in one of the newer functions and I did not properly have a way to print that log. The result was that I had a source return 0 results but no way to know that because I was changing the copy of the slice not the slice in memory. 